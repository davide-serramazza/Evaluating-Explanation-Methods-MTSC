{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c656715-20ff-4589-bb75-c45747008b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def minMax_normalization(X):\n",
    "    X = (X - X.min() ) / (X.max() - X.min())\n",
    "    return X*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04d2c2-51bd-4374-960b-10795d1bdffb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font size=5> load metadata, shape and dCam explanations </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84502db4-e0a2-467b-b549-c02a934cd701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ns = [\"PseudoPeriodic\",\"GaussianProcess\", \"AutoRegressive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d802fd-0568-428a-84dc-6164f808768a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset metadata\n",
    "dir_name = \"../data/synth_data/data/\"\n",
    "names=[\"SimulatedTestingMetaData_RareTime_PseudoPeriodic_F_20_TS_100_Positional_False.npy\"\n",
    "      ,\"SimulatedTestingMetaData_RareTime_GaussianProcess_F_20_TS_100_Positional_False.npy\",\n",
    "      \"SimulatedTestingMetaData_RareTime_AutoRegressive_F_20_TS_100_Positional_False.npy\"]\n",
    "metadata = [np.load(dir_name+n , allow_pickle=True).item() for n in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c709335-df87-4f5e-aecc-fff4d4b2cd4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load synthetic channel by channel\n",
    "import copy\n",
    "dir_name=\"rocket_shap_results/\"\n",
    "names=[\"PseudoPeriodic_Positional_False_Concatenated_200.npy\",\"GaussianProcess_Positional_False_Concatenated_200.npy\",\n",
    "           \"AutoRegressive_Positional_False_Concatenated_200.npy\"]\n",
    "exps_concat = [np.load(dir_name+n,allow_pickle=True).item() for n in names]\n",
    "for i in range(3):\n",
    "    exps_concat[i][\"exps\"] = exps_concat[i][\"exps\"].reshape(100,2,20,10).transpose([0,2,1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02554bac-5209-45f5-8ba0-a2c0c2af90ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "#load synthetic channel by channel\n",
    "dir_name=\"rocket_shap_results/\"\n",
    "names=[\"PseudoPeriodic_Positional_False_ChannelByChannel.npy\",\"GaussianProcess_Positional_False_channelByChannel.npy\",\n",
    "           \"AutoRegressive_Positional_False_channelByChannel.npy\"]\n",
    "exps = [np.load(dir_name+n,allow_pickle=True).item() for n in names]\n",
    "exps[2].keys()\n",
    "print( exps[2][\"exps\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0d243-79fd-48a7-8414-6b7abf56af59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ee9dea-a205-4625-9276-b885d995bb39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20, 2, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps[0][\"exps\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81c253c-0e5e-476b-bbe6-3cb55b288a4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dcam_tl', 'permutation_success_tl', 'dcam_ol', 'permutation_success_ol', 'ground_truth_label', 'output_label'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dCAM synthetic\n",
    "dir_name = \"../explanations/dCAM_results/\"\n",
    "ns=[\"PseudoPeriodic_Positional_False_explenations.npy\",\"GaussianProcess_Positional_False_explenations.npy\"\n",
    "    ,\"AutoRegressive_Positional_False_explenations.npy\"]#,\"MP_old_explenations.npy\"]\n",
    "dCAM_data = [np.load(dir_name+n , allow_pickle=True) for n in ns]\n",
    "dCAM_data[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb663b7-af10-4e03-b38f-fc988874274b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix,average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01880e-6efe-4038-95e2-061563926c3f",
   "metadata": {},
   "source": [
    "<font size=5> evaluate starting from shap </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e275f7-6ade-4e87-9604-71fe034d4caa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PseudoPeriodic_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.1471;\t  recall is 0.5000; \t f1 is 0.2273 \n",
      "\t micro: precision is 0.0500;\t  recall is 0.5000; \t f1 is 0.0909 \n",
      "\t macro AUC is 0.9909;\t micro AUC is 0.9909 \n",
      "\t macro ROC is 0.9995;\t  micro ROC 0.9995; \n",
      "\n",
      "PseudoPeriodic_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.2083;\t  recall is 0.5000; \t f1 is 0.2941 \n",
      "\t micro: precision is 0.0500;\t  recall is 0.5000; \t f1 is 0.0909 \n",
      "\t macro AUC is 0.9497;\t micro AUC is 0.9497 \n",
      "\t macro ROC is 0.9974;\t  micro ROC 0.9974; \n",
      "\n",
      "PseudoPeriodic_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.5003;\t  recall is 0.5000; \t f1 is 0.5001 \n",
      "\t micro: precision is 0.4995;\t  recall is 0.5051; \t f1 is 0.5023 \n",
      "\t macro AUC is 0.6326;\t micro AUC is 0.6326 \n",
      "\t macro ROC is 0.9732;\t  micro ROC 0.9732; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.3044;\t  recall is 0.4460; \t f1 is 0.3619 \n",
      "\t micro: precision is 0.0384;\t  recall is 0.4460; \t f1 is 0.0708 \n",
      "\t macro AUC is 0.0823;\t micro AUC is 0.0823 \n",
      "\t macro ROC is 0.1858;\t  micro ROC 0.1858; \n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.0526;\t  recall is 0.4720; \t f1 is 0.0946 \n",
      "\t micro: precision is 0.0429;\t  recall is 0.4720; \t f1 is 0.0786 \n",
      "\t macro AUC is 0.0501;\t micro AUC is 0.0501 \n",
      "\t macro ROC is 0.2968;\t  micro ROC 0.2968; \n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.3558;\t  recall is 0.1460; \t f1 is 0.2070 \n",
      "\t micro: precision is 0.2932;\t  recall is 0.1460; \t f1 is 0.1949 \n",
      "\t macro AUC is 0.3451;\t micro AUC is 0.3451 \n",
      "\t macro ROC is 0.9395;\t  micro ROC 0.9395; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.2929;\t  recall is 0.5120; \t f1 is 0.3726 \n",
      "\t micro: precision is 0.0540;\t  recall is 0.5120; \t f1 is 0.0977 \n",
      "\t macro AUC is 0.7047;\t micro AUC is 0.7047 \n",
      "\t macro ROC is 0.8516;\t  micro ROC 0.8516; \n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.0283;\t  recall is 0.5600; \t f1 is 0.0538 \n",
      "\t micro: precision is 0.0501;\t  recall is 0.5600; \t f1 is 0.0920 \n",
      "\t macro AUC is 0.0964;\t micro AUC is 0.0964 \n",
      "\t macro ROC is 0.6200;\t  micro ROC 0.6200; \n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.3270;\t  recall is 0.1480; \t f1 is 0.2038 \n",
      "\t micro: precision is 0.2676;\t  recall is 0.1480; \t f1 is 0.1906 \n",
      "\t macro AUC is 0.0625;\t micro AUC is 0.0625 \n",
      "\t macro ROC is 0.5689;\t  micro ROC 0.5689; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def average_ts(ts):\n",
    "    avg_ts = np.zeros(shape=(20,10), dtype=ts.dtype)\n",
    "    for i in range(avg_ts.shape[0]):\n",
    "        for j in range(avg_ts.shape[1]):\n",
    "            avg_ts[i][j] = np.average(ts[i][j*10 : (j+1)*10])\n",
    "    return avg_ts\n",
    "\n",
    "threshold = 50\n",
    "\n",
    "for i in range(3):\n",
    "    for method in [\"SHAP_ch\", \"SHAP_co\",\"dCAM\"]:\n",
    "        \n",
    "        # initalise counters \n",
    "        metrics = {\n",
    "            \"macro\": { \"pr\" : 0,\"rec\" :0, \"f1\":0, \"PRAUC\":0,\"ROC\":0},\n",
    "            \"micro\" : {\"tp\":0,\"fp\":0,\"fn\":0}\n",
    "        }\n",
    "        \n",
    "        #read the correct data structure \n",
    "        if method==\"SHAP_ch\":#exps_concat1\n",
    "            # shap\n",
    "            Xps = exps[i][\"exps\"]\n",
    "            test_length = Xps.shape[0]\n",
    "        elif method==\"SHAP_co\":\n",
    "            # shap\n",
    "            Xps = exps_concat[i][\"exps\"]\n",
    "            test_length = Xps.shape[0]\n",
    "        elif method==\"dCAM\":\n",
    "            Xps = dCAM_data[i]\n",
    "\n",
    "        # loop over test data\n",
    "        test_length = Xps.shape[0]\n",
    "        for j in range(test_length):\n",
    "            if method==\"SHAP_ch\":\n",
    "                # shap\n",
    "                true_classes = exps[i][\"ground_truth_labels\"][i,:]\n",
    "                out_classes = exps[i][\"model_outputs\"][i]\n",
    "                orig_current_expl = Xps[i,:, int(out_classes[j]) , : ]\n",
    "            elif method==\"SHAP_co\":\n",
    "                # shap\n",
    "                true_classes = exps_concat[i][\"ground_truth_labels\"]\n",
    "                out_classes = exps_concat[i][\"model_outputs\"]\n",
    "                orig_current_expl = Xps[i,:, int(out_classes[j]) , : ]\n",
    "            elif method==\"dCAM\":\n",
    "                if np.any(Xps[j][\"dcam_ol\"]==-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    true_classes = Xps[j][\"ground_truth_label\"]\n",
    "                    out_classes =  Xps[j][\"output_label\"]\n",
    "                    current_expl = Xps[j][\"dcam_ol\"]\n",
    "                    orig_current_expl = average_ts(current_expl)\n",
    "                    \n",
    "            current_expl = minMax_normalization(orig_current_expl)\n",
    "            importants = (current_expl>=threshold).astype(int)\n",
    "            mask = np.zeros(shape=(20,10),dtype=int)\n",
    "            mask[:10,1]=1\n",
    "            importants = importants.flatten(); mask = mask.flatten()\n",
    "\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                mask, importants,beta=1.0, average=\"binary\",pos_label=1)\n",
    "            tn,fp,fn,tp= confusion_matrix(mask, importants).ravel()\n",
    "            \n",
    "            macro_PR_AUC = average_precision_score(mask,orig_current_expl.flatten(),average=\"macro\")\n",
    "            micro_PR_AUC = average_precision_score(mask,orig_current_expl.flatten(),average=\"weighted\")\n",
    "\n",
    "            macro_ROC_AUC = roc_auc_score(mask,orig_current_expl.flatten(),average=\"macro\")\n",
    "            micro_ROC_AUC = roc_auc_score(mask, orig_current_expl.flatten() ,average=\"weighted\")\n",
    "            \n",
    "            metrics[\"macro\"][\"pr\"]+=precision;\n",
    "            metrics[\"macro\"][\"rec\"]+=recall; \n",
    "            metrics[\"macro\"][\"f1\"]+=f1; \n",
    "            metrics[\"micro\"][\"tp\"]+=tp;\n",
    "            metrics[\"micro\"][\"fp\"]+=fp; \n",
    "            metrics[\"micro\"][\"fn\"]+=fn; \n",
    "            \n",
    "        #average\n",
    "        micro_precision = metrics[\"micro\"][\"tp\"] / (metrics[\"micro\"][\"tp\"] +metrics[\"micro\"][\"fp\"])\n",
    "        micro_recall = metrics[\"micro\"][\"tp\"] / (metrics[\"micro\"][\"tp\"] +metrics[\"micro\"][\"fn\"])\n",
    "        micro_f1 = 2*(micro_precision*micro_recall) / (micro_precision + micro_recall)\n",
    "        \n",
    "        macro_precision = metrics[\"macro\"][\"pr\"]/test_length \n",
    "        macro_recall =  metrics[\"macro\"][\"rec\"]/test_length \n",
    "        # TODO how to compute macro f1?\n",
    "        macro_f1 = 2*(macro_precision*macro_recall) / (macro_precision + macro_recall)       \n",
    "        \n",
    "        # TODO check macro f1\n",
    "        print(ns[i] ,\"\\t\",method, '\\n\\t macro: precision is {:.4f};\\t  recall is {:.4f}; \\t f1 is {:.4f}'.format(\n",
    "            macro_precision,macro_recall,macro_f1),\n",
    "            '\\n\\t micro: precision is {:.4f};\\t  recall is {:.4f}; \\t f1 is {:.4f}'.format(micro_precision,micro_recall,\n",
    "            micro_f1),\n",
    "              '\\n\\t macro AUC is {:.4f};\\t micro AUC is {:.4f}'.format(macro_PR_AUC,micro_PR_AUC),\n",
    "              '\\n\\t macro ROC is {:.4f};\\t  micro ROC {:.4f};'.format(macro_ROC_AUC,micro_ROC_AUC),\n",
    "              \"\\n\")\n",
    "    print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60767a8e-8d72-4deb-934c-0e55a4369187",
   "metadata": {},
   "source": [
    "<font size=5> evaluate starting from dCAM </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9a9bf8-c2c7-4266-9ffc-4417a3feeb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def repeat_ts(ts):\n",
    "    return np.repeat(ts,10).reshape(ts.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6395e17b-5a73-4cb2-8bbc-7f2ac9ba2ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PseudoPeriodic_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.1471;\t  recall is 0.5000; \t f1 is 0.2273 \n",
      "\t micro: precision is 0.0500;\t  recall is 0.5000; \t f1 is 0.0909 \n",
      "\t macro AUC is 0.9909;\t micro AUC is 0.9909 \n",
      "\t macro ROC is 0.9995;\t  micro ROC 0.9995; \n",
      "\n",
      "\n",
      "PseudoPeriodic_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.2083;\t  recall is 0.5000; \t f1 is 0.2941 \n",
      "\t micro: precision is 0.0500;\t  recall is 0.5000; \t f1 is 0.0909 \n",
      "\t macro AUC is 0.9497;\t micro AUC is 0.9497 \n",
      "\t macro ROC is 0.9974;\t  micro ROC 0.9974; \n",
      "\n",
      "\n",
      "PseudoPeriodic_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.4943;\t  recall is 0.2590; \t f1 is 0.3399 \n",
      "\t micro: precision is 0.4839;\t  recall is 0.2616; \t f1 is 0.3396 \n",
      "\t macro AUC is 0.5290;\t micro AUC is 0.5290 \n",
      "\t macro ROC is 0.9685;\t  micro ROC 0.9685; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.3044;\t  recall is 0.4460; \t f1 is 0.3619 \n",
      "\t micro: precision is 0.0384;\t  recall is 0.4460; \t f1 is 0.0708 \n",
      "\t macro AUC is 0.0823;\t micro AUC is 0.0823 \n",
      "\t macro ROC is 0.1858;\t  micro ROC 0.1858; \n",
      "\n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.0526;\t  recall is 0.4720; \t f1 is 0.0946 \n",
      "\t micro: precision is 0.0429;\t  recall is 0.4720; \t f1 is 0.0786 \n",
      "\t macro AUC is 0.0501;\t micro AUC is 0.0501 \n",
      "\t macro ROC is 0.2968;\t  micro ROC 0.2968; \n",
      "\n",
      "\n",
      "GaussianProcess_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.3155;\t  recall is 0.0711; \t f1 is 0.1160 \n",
      "\t micro: precision is 0.2752;\t  recall is 0.0711; \t f1 is 0.1130 \n",
      "\t macro AUC is 0.2827;\t micro AUC is 0.2827 \n",
      "\t macro ROC is 0.9300;\t  micro ROC 0.9300; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t SHAP_ch \n",
      "\t macro: precision is 0.2773;\t  recall is 0.5000; \t f1 is 0.3567 \n",
      "\t micro: precision is 0.0500;\t  recall is 0.5000; \t f1 is 0.0909 \n",
      "\t macro AUC is 0.7047;\t micro AUC is 0.7047 \n",
      "\t macro ROC is 0.8516;\t  micro ROC 0.8516; \n",
      "\n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t SHAP_co \n",
      "\t macro: precision is 0.0283;\t  recall is 0.5600; \t f1 is 0.0538 \n",
      "\t micro: precision is 0.0501;\t  recall is 0.5600; \t f1 is 0.0920 \n",
      "\t macro AUC is 0.0964;\t micro AUC is 0.0964 \n",
      "\t macro ROC is 0.6200;\t  micro ROC 0.6200; \n",
      "\n",
      "\n",
      "AutoRegressive_Positional_False_explenations.npy \t dCAM \n",
      "\t macro: precision is 0.3216;\t  recall is 0.0710; \t f1 is 0.1163 \n",
      "\t micro: precision is 0.2555;\t  recall is 0.0710; \t f1 is 0.1111 \n",
      "\t macro AUC is 0.0554;\t micro AUC is 0.0554 \n",
      "\t macro ROC is 0.5692;\t  micro ROC 0.5692; \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 50\n",
    "\n",
    "for i in range(3):\n",
    "    for method in [\"SHAP_ch\",\"SHAP_co\",\"dCAM\"]:\n",
    "        \n",
    "        # initalise counters \n",
    "        metrics = {\n",
    "            \"macro\": { \"pr\" : 0,\"rec\" :0, \"f1\":0, \"PRAUC\":0,\"ROC\":0},\n",
    "            \"micro\" : {\"tp\":0,\"fp\":0,\"fn\":0}\n",
    "        }\n",
    "        \n",
    "        #read the correct data structure \n",
    "        if method==\"SHAP_ch\":\n",
    "            # shap\n",
    "            Xps = exps[i][\"exps\"]\n",
    "            test_length = Xps.shape[0]\n",
    "        elif method==\"SHAP_co\":\n",
    "            # shap\n",
    "            Xps = exps_concat[i][\"exps\"]\n",
    "            test_length = Xps.shape[0]\n",
    "        elif method==\"dCAM\":\n",
    "            Xps = dCAM_data[i]\n",
    "\n",
    "        # loop over test data\n",
    "        test_length = Xps.shape[0]\n",
    "        for j in range(test_length):\n",
    "            if method==\"SHAP_ch\":\n",
    "                # shap\n",
    "                true_classes = exps[i][\"ground_truth_labels\"][0,:]\n",
    "                out_classes = exps[i][\"model_outputs\"][0]\n",
    "                orig_current_expl = repeat_ts( Xps[i,:, int(out_classes[j]) , : ] )\n",
    "            elif method==\"SHAP_co\":\n",
    "                # shap\n",
    "                true_classes = exps_concat[i][\"ground_truth_labels\"]\n",
    "                out_classes = exps_concat[i][\"model_outputs\"]\n",
    "                orig_current_expl =  repeat_ts( Xps[i,:, int(out_classes[j]) , : ] )\n",
    "            elif method==\"dCAM\":\n",
    "                if np.any(Xps[j][\"dcam_ol\"]==-1):\n",
    "                    continue\n",
    "                else:\n",
    "                    true_classes = Xps[j][\"ground_truth_label\"]\n",
    "                    out_classes =  Xps[j][\"output_label\"]\n",
    "                    orig_current_expl = Xps[j][\"dcam_ol\"]\n",
    "\n",
    "                    \n",
    "            current_expl = minMax_normalization(orig_current_expl)\n",
    "            importants = (current_expl>=threshold).astype(int)\n",
    "            mask = np.zeros(shape=(20,100),dtype=int)\n",
    "            mask[:10,10:20]=1\n",
    "            importants = importants.flatten(); mask = mask.flatten()\n",
    "\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                mask, importants,beta=1.0, average=\"binary\",pos_label=1)\n",
    "            tn,fp,fn,tp= confusion_matrix(mask, importants).ravel()\n",
    "            \n",
    "            macro_PR_AUC = average_precision_score(mask,orig_current_expl.flatten(),average=\"macro\")\n",
    "            micro_PR_AUC = average_precision_score(mask,orig_current_expl.flatten(),average=\"weighted\")\n",
    "\n",
    "            macro_ROC_AUC = roc_auc_score(mask,orig_current_expl.flatten(),average=\"macro\")\n",
    "            micro_ROC_AUC = roc_auc_score(mask, orig_current_expl.flatten() ,average=\"weighted\")\n",
    "            \n",
    "            metrics[\"macro\"][\"pr\"]+=precision;\n",
    "            metrics[\"macro\"][\"rec\"]+=recall; \n",
    "            metrics[\"macro\"][\"f1\"]+=f1; \n",
    "            metrics[\"micro\"][\"tp\"]+=tp;\n",
    "            metrics[\"micro\"][\"fp\"]+=fp; \n",
    "            metrics[\"micro\"][\"fn\"]+=fn; \n",
    "            \n",
    "        #average\n",
    "        micro_precision = metrics[\"micro\"][\"tp\"] / (metrics[\"micro\"][\"tp\"] +metrics[\"micro\"][\"fp\"])\n",
    "        micro_recall = metrics[\"micro\"][\"tp\"] / (metrics[\"micro\"][\"tp\"] +metrics[\"micro\"][\"fn\"])\n",
    "        micro_f1 = 2*(micro_precision*micro_recall) / (micro_precision + micro_recall)\n",
    "        \n",
    "        macro_precision = metrics[\"macro\"][\"pr\"]/test_length \n",
    "        macro_recall =  metrics[\"macro\"][\"rec\"]/test_length \n",
    "        # TODO how to compute macro f1?\n",
    "        macro_f1 = 2*(macro_precision*macro_recall) / (macro_precision + macro_recall)       \n",
    "        \n",
    "        # TODO check macro f1\n",
    "        print(ns[i] ,\"\\t\",method, '\\n\\t macro: precision is {:.4f};\\t  recall is {:.4f}; \\t f1 is {:.4f}'.format(\n",
    "            macro_precision,macro_recall,macro_f1),\n",
    "            '\\n\\t micro: precision is {:.4f};\\t  recall is {:.4f}; \\t f1 is {:.4f}'.format(micro_precision,micro_recall,\n",
    "            micro_f1),\n",
    "              '\\n\\t macro AUC is {:.4f};\\t micro AUC is {:.4f}'.format(macro_PR_AUC,micro_PR_AUC),\n",
    "              '\\n\\t macro ROC is {:.4f};\\t  micro ROC {:.4f};'.format(macro_ROC_AUC,micro_ROC_AUC),\n",
    "              \"\\n\\n\")\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4919ea-b1a0-45db-82fe-2a6f2f0c90fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7c608-e552-426a-b3b6-203520dbe03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "045590a0-714d-40f0-96cb-409cc7072d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99]\n",
      " [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      "  118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      "  136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
      "  154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
      "  172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
      "  190 191 192 193 194 195 196 197 198 199]] \n",
      " (2, 100)\n",
      "\n",
      "\n",
      "after concat (1, 200)\n",
      "\n",
      "\n",
      "to original dim [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99]\n",
      " [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      "  118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      "  136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153\n",
      "  154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171\n",
      "  172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189\n",
      "  190 191 192 193 194 195 196 197 198 199]] (2, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np_array,\"\\n\", np_array.shape)\n",
    "np_array_concat_np = np_array.reshape(1,-1)\n",
    "print(\"\\n\\nafter concat\",np_array_concat_np.shape)\n",
    "\n",
    "print( \"\\n\\nto original dim\",np_array_concat_np.reshape(2,100), np_array_concat_np.reshape(2,100).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cedd2cdb-d4e4-42e1-9749-d1ff80bce71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_single_explanation(x, w, savefig=False):\n",
    "    \"\"\"Visualize one time series with explanation by a heatmap\n",
    "    Args:\n",
    "        idx: Index of the example to produce heatmap (0-indexed)\n",
    "        X_series: the X_series that needs to visualize (2d array)\n",
    "        explanation: coressponding explanation weights for the X_series\n",
    "        ds: the name of the dataset to explain (for annotation purpose only)\n",
    "\n",
    "    Return: a plot of heatmap explanation for an example index in a given dataset\n",
    "    \"\"\"\n",
    "    def transform(X):\n",
    "        ma,mi = np.max(X), np.min(X)\n",
    "        X = (X - mi)/(ma-mi)\n",
    "        return X*100\n",
    "    weight = abs(w)\n",
    "    weight = transform(weight)\n",
    "    # z = np.histogram(weight)\n",
    "    # plt.hist(weight, bins = [0,20,40,60,80,100]) \n",
    "    # plt.title(\"histogram\") \n",
    "    # plt.show()\n",
    "    ts = np.squeeze(x)\n",
    "        \n",
    "    max_length1, max_length2 = len(ts),10000 #\n",
    "    x1 = np.linspace(0,max_length1,num = max_length1)\n",
    "    x2 = np.linspace(0,max_length1,num = max_length2)\n",
    "    y1 = ts\n",
    "    \n",
    "    f = interp1d(x1, y1) # interpolate time series\n",
    "    fcas = interp1d(x1, weight) # interpolate weight color\n",
    "    weight = fcas(x2) # convert vector of original weight vector to new weight vector\n",
    "\n",
    "    plt.scatter(x2,f(x2), c = weight, cmap = 'jet', marker='.', s= 1,vmin=0,vmax = 100)\n",
    "    # plt.xlabel('Explanation for index %d, dataset %s' %(idx, ds))\n",
    "    cbar = plt.colorbar(orientation = 'vertical')\n",
    "    \n",
    "    if savefig:\n",
    "        plt.savefig('temp.pdf',format='pdf',dpi=300)\n",
    "    else: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c5722-628c-4248-a35d-793e269e41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_exp = \"../../Trang/first_experiment/explanations/rocket_shap_results/MP_Concatenated4_10.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96cd354-576b-42a1-b9af-10c086d1f4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74b333fc-ea9c-46b3-b0be-42c383c06685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_single_explanation(x, w, savefig=False):\n",
    "    \"\"\"Visualize one time series with explanation by a heatmap\n",
    "    Args:\n",
    "        idx: Index of the example to produce heatmap (0-indexed)\n",
    "        X_series: the X_series that needs to visualize (2d array)\n",
    "        explanation: coressponding explanation weights for the X_series\n",
    "        ds: the name of the dataset to explain (for annotation purpose only)\n",
    "\n",
    "    Return: a plot of heatmap explanation for an example index in a given dataset\n",
    "    \"\"\"\n",
    "    def transform(X):\n",
    "        ma,mi = np.max(X), np.min(X)\n",
    "        X = (X - mi)/(ma-mi)\n",
    "        return X*100\n",
    "    weight = abs(w)\n",
    "    weight = transform(weight)\n",
    "    # z = np.histogram(weight)\n",
    "    # plt.hist(weight, bins = [0,20,40,60,80,100]) \n",
    "    # plt.title(\"histogram\") \n",
    "    # plt.show()\n",
    "    ts = np.squeeze(x)\n",
    "        \n",
    "    max_length1, max_length2 = len(ts),10000 #\n",
    "    x1 = np.linspace(0,max_length1,num = max_length1)\n",
    "    x2 = np.linspace(0,max_length1,num = max_length2)\n",
    "    y1 = ts\n",
    "    \n",
    "    f = interp1d(x1, y1) # interpolate time series\n",
    "    fcas = interp1d(x1, weight) # interpolate weight color\n",
    "    weight = fcas(x2) # convert vector of original weight vector to new weight vector\n",
    "\n",
    "    plt.scatter(x2,f(x2), c = weight, cmap = 'jet', marker='.', s= 1,vmin=0,vmax = 100)\n",
    "    # plt.xlabel('Explanation for index %d, dataset %s' %(idx, ds))\n",
    "    cbar = plt.colorbar(orientation = 'vertical')\n",
    "    \n",
    "    if savefig:\n",
    "        plt.savefig('temp.pdf',format='pdf',dpi=300)\n",
    "    else: plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb24febf-b317-4218-a07f-49cbed29b0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CMJ_slices = [  0 , 59, 119, 178, 238, 298 ,357, 417, 476, 536, 596]\n",
    "MP_slices = [  0,  16,  32,  48,  64,  80,  96, 112, 128, 144, 161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2ad295f4-3a8b-4724-922a-9eefe10f3297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset metadata\n",
    "import os\n",
    "w = [np.load(\"rocket_shap_results/CMJ_ChannelByChannel.npy\", allow_pickle=True).item(),\n",
    "        np.load( \"dCAM_results/CMJ_explenations.npy\", allow_pickle=True) \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3cc8dda-2777-46be-a284-9cdab3613cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel 0 has accuracy 0.7877094972067039\n",
      "channel 1 has accuracy 0.8491620111731844\n",
      "channel 2 has accuracy 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "tmp = (w[0][\"model_outputs\"] == w[0][\"ground_truth_labels\"])\n",
    "for i  in range(3):\n",
    "    acc = np.sum(tmp[i]) / w[0][\"model_outputs\"].shape[1]\n",
    "    print(\"channel\", i ,\"has accuracy\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ad2cfd5b-c0d8-4936-8014-faa8d2b427a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dcam_tl', 'permutation_success_tl', 'dcam_ol', 'permutation_success_ol', 'ground_truth_label', 'output_label'])\n",
      "1415 1592 1420 \t 0.8888190954773869 1.0 0.8919597989949749 \t\t 56\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "dCAM = w[1]\n",
    "print( dCAM[0].keys() )\n",
    "ch_zero = 0; ch_one = 0; ch_two = 0\n",
    "no_diffs = 0\n",
    "for i in range(179):\n",
    "    ts = minMax_normalization( dCAM[i][\"dcam_ol\"])\n",
    "    if norm( ts[0] - ts[1]) < 1e-13 and norm( ts[2] - ts[1]) < 1e-13 and norm( ts[0] - ts[2]) < 1e-13:\n",
    "        no_diffs +=1\n",
    "    importants = np.where (ts >= 50)\n",
    "    ch_zero += np.sum(importants[0]==0) \n",
    "    ch_one += np.sum(importants[0]==1)\n",
    "    ch_two += np.sum(importants[0]==2)\n",
    "    \n",
    "print(ch_zero, ch_one, ch_two, \"\\t\", ch_zero/ch_one, ch_one/ch_one, ch_two/ch_one, \"\\t\\t\",no_diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "20b97c10-643b-45f7-977e-d7a84ff6224b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 10) ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'] ['2' '2' '2' '2' '0' '2' '0' '2' '2' '0' '0' '0' '0' '0' '1' '2' '0' '0'\n",
      " '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '2' '0' '1' '1' '1' '1' '1' '1' '1' '0' '1' '0' '1' '1'\n",
      " '0' '1' '2' '1' '0' '1' '2' '2' '2' '1' '0' '0' '0' '2' '0' '1' '0' '0'\n",
      " '1' '0' '0' '2' '1' '1' '1' '1' '1' '1' '2' '1' '1' '0' '1' '1' '1' '1'\n",
      " '1' '1' '0' '0' '0' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '0' '2' '2' '2' '0' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2']\n",
      "(3, 3, 10) ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'] ['2' '2' '2' '0' '0' '2' '2' '2' '2' '0' '0' '2' '0' '2' '2' '2' '2' '2'\n",
      " '2' '2' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '2' '0' '1' '1' '0' '1' '0' '2' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '1' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '1' '2' '2' '2' '2' '2' '2' '2' '1' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2']\n",
      "(3, 3, 10) ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'] ['0' '0' '2' '0' '2' '0' '2' '2' '2' '0' '2' '0' '0' '0' '2' '2' '2' '0'\n",
      " '1' '2' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '2' '0' '2' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '1' '0' '1' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '0' '1' '0' '1' '0' '1' '1'\n",
      " '0' '1' '1' '1' '0' '1' '0' '2' '0' '1' '1' '0' '1' '0' '1' '1' '1' '1'\n",
      " '0' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '1' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 2\u001b[0m     gt \u001b[38;5;241m=\u001b[39m \u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truth_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m     ot \u001b[38;5;241m=\u001b[39m w[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m( w[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexps\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\u001b[38;5;241m.\u001b[39mshape ,gt,ot)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "for i in range(w[0][\"exps\"].shape[0]):\n",
    "    gt = w[0][\"ground_truth_labels\"][i]\n",
    "    ot = w[0][\"model_outputs\"][i]\n",
    "    print( w[0][\"exps\"][i].shape ,gt,ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4389a-6317-4cae-bef2-3336a5523dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
